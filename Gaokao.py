'''
è€ƒç ”æ‹©æ ¡åŠ©æ‰‹ - ä¸“ä¸šä¼˜åŒ–ç‰ˆ
'''




from openai import OpenAI, Stream
import streamlit as st
from typing import Generator, Optional, List, Union
from openai.types.chat import (
    ChatCompletion,
    ChatCompletionChunk,
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionToolMessageParam,
    ChatCompletionFunctionMessageParam
)

# å…¨å±€é…ç½®
PROVINCES = ['åŒ—äº¬', 'å¤©æ´¥', 'æ²³åŒ—', 'å±±è¥¿', 'å†…è’™å¤', 'è¾½å®', 'å‰æ—', 'é»‘é¾™æ±Ÿ', 'ä¸Šæµ·', 'æ±Ÿè‹', 'æµ™æ±Ÿ', 'å®‰å¾½', 'ç¦å»º', 'æ±Ÿè¥¿', 'å±±ä¸œ', 'æ²³å—', 'æ¹–åŒ—', 'æ¹–å—', 'å¹¿ä¸œ', 'å¹¿è¥¿', 'æµ·å—', 'é‡åº†', 'å››å·', 'è´µå·', 'äº‘å—', 'è¥¿è—', 'é™•è¥¿', 'ç”˜è‚ƒ', 'é’æµ·', 'å®å¤', 'æ–°ç–†', 'é¦™æ¸¯', 'æ¾³é—¨', 'å°æ¹¾']
SUBJECT_TYPES = ["æ–‡ç§‘", "ç†å·¥ç§‘", "ç»ç®¡ç±»", "åŒ»å­¦ç±»", "è‰ºæœ¯ç±»"]
INTEREST_EXAMPLES = "å¦‚ï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ã€ä¸´åºŠåŒ»å­¦ã€é‡‘èå­¦ã€æ³•å¾‹ç¡•å£«ã€æ•™è‚²å­¦"

# åˆå§‹åŒ–å…¨å±€å˜é‡
base_url: str = ""
model_name: str = ""

MessageParam = Union[
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionToolMessageParam,
    ChatCompletionFunctionMessageParam
]

def get_llm_response(
    client: OpenAI,
    model: str,
    user_prompt: str,
    system_prompt: Optional[str] = None,
    stream: bool = False
) -> Union[ChatCompletion, Stream[ChatCompletionChunk]]:
    """
    è·å–å¤§è¯­è¨€æ¨¡å‹å“åº”

    Args:
        client: OpenAIå®¢æˆ·ç«¯å®ä¾‹
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        user_prompt: ç”¨æˆ·æç¤ºè¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯(å¯é€‰)
        stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º

    Returns:
        èŠå¤©å®Œæˆå¯¹è±¡æˆ–æµå¼å“åº”

    Raises:
        RuntimeError: å½“APIè¯·æ±‚å¤±è´¥æ—¶
    """
    messages: List[ChatCompletionSystemMessageParam] = [
        dict["role": "user", "content": user_prompt]  # type: ignore
    ]

    if system_prompt:
        messages.insert(0, {"role": "system", "content": system_prompt})  # type: ignore

    try:
        return client.chat.completions.create(
            model=model,
            messages=messages,  # type: ignore
            stream=stream,
            temperature=0.7
        )
    except Exception as exc:
        raise RuntimeError(f"AIæœåŠ¡è¯·æ±‚å¤±è´¥: {str(exc)}")

def get_advice(
    question: str,
    score: int,
    province: str,
    interests: str,
    subject_type: str
) -> Generator[str, None, None]:
    """
    æ™ºèƒ½ç”Ÿæˆè€ƒç ”æ‹©æ ¡å»ºè®®ï¼ˆæµå¼è¾“å‡ºï¼‰

    Args:
        question: ç”¨æˆ·å’¨è¯¢é—®é¢˜
        score: åˆè¯•æ€»åˆ†(200-500)
        province: ç›®æ ‡é™¢æ ¡çœä»½
        interests: ç ”ç©¶æ–¹å‘
        subject_type: å­¦ç§‘é—¨ç±»

    Yields:
        å»ºè®®å†…å®¹å­—ç¬¦ä¸²
    """
    try:
        if not 200 <= score <= 500:
            yield "âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„è€ƒç ”åˆè¯•åˆ†æ•°ï¼ˆ200-500ä¹‹é—´ï¼‰"
            return

        try:
            api_key = st.secrets['API_KEY']
            if not api_key.startswith(('sk-', 'lsk-')):
                raise ValueError("æ— æ•ˆçš„APIå¯†é’¥æ ¼å¼")
        except Exception as e:
            yield f"âš ï¸ APIå¯†é’¥é…ç½®é”™è¯¯: {str(e)}"
            return

        prompt = f"""ä½œä¸ºè€ƒç ”æ‹©æ ¡ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯æä¾›ä¸“ä¸šå»ºè®®ï¼š

è€ƒç”Ÿæ¡£æ¡ˆï¼š
- ç›®æ ‡çœä»½ï¼š{province}
- åˆè¯•æ€»åˆ†ï¼š{score}åˆ†ï¼ˆ{_get_score_level(score)}ï¼‰
- å­¦ç§‘é—¨ç±»ï¼š{subject_type}
- ç ”ç©¶æ–¹å‘ï¼š{interests}

å’¨è¯¢é—®é¢˜ï¼š{question}

è¯·æŒ‰ä»¥ä¸‹æ¡†æ¶å›ç­”ï¼š
1. ã€åˆ†æ•°å®šä½ã€‘è¯¥åˆ†æ•°åœ¨ç›®æ ‡é™¢æ ¡å±‚æ¬¡çš„ç«äº‰åŠ›åˆ†æ
2. ã€é™¢æ ¡æ¨èã€‘å»ºè®®æŠ¥è€ƒçš„985/211/åŒéé™¢æ ¡æ¢¯é˜Ÿ
3. ã€ä¸“ä¸šåˆ†æã€‘ç ”ç©¶æ–¹å‘å¯¹åº”çš„å¯¼å¸ˆå›¢é˜Ÿå’Œå­¦ç§‘æ’å
4. ã€å¤è¯•å»ºè®®ã€‘è¯¥åˆ†æ•°æ®µçš„å¤è¯•å‡†å¤‡é‡ç‚¹
5. ã€è°ƒå‰‚ç­–ç•¥ã€‘å¦‚éœ€è°ƒå‰‚çš„å¤‡é€‰æ–¹æ¡ˆ"""

        client = OpenAI(
            base_url=base_url,
            api_key=api_key
        )

        stream = get_llm_response(
            client=client,
            model=model_name,
            user_prompt=prompt,
            system_prompt="ä½ æ˜¯ä¸€åèµ„æ·±è€ƒç ”è§„åˆ’å¸ˆï¼Œå›ç­”éœ€ï¼š1.ç»“åˆå­¦ç§‘è¯„ä¼° 2.å…³æ³¨å¯¼å¸ˆèµ„æº 3.åˆ†ç‚¹æ¸…æ™°",
            stream=True
        )

        for chunk in stream:
            content = chunk.choices[0].delta.content or ''
            yield content

    except Exception as exc:
        yield f"âš ï¸ æœåŠ¡é”™è¯¯ï¼š{type(exc).__name__} - {str(exc)}"

def _get_score_level(score: int) -> str:
    """è€ƒç ”åˆ†æ•°ç­‰çº§è¯„ä¼°"""
    if score >= 400: return "ğŸ–ï¸ é¡¶å°–æ°´å¹³ï¼ˆå¯å†²985 topä¸“ä¸šï¼‰"
    elif score >= 350: return "ğŸ… ä¼˜ç§€æ°´å¹³ï¼ˆé‡ç‚¹211ä¼˜åŠ¿ä¸“ä¸šï¼‰"
    elif score >= 300: return "ğŸ“š ä¸­ç­‰æ°´å¹³ï¼ˆæ™®é€šä¸€æœ¬ä¸»åŠ›åŒºé—´ï¼‰"
    return "ğŸ“Œ è¿‡çº¿æ°´å¹³ï¼ˆéœ€å…³æ³¨è°ƒå‰‚æœºä¼šï¼‰"

# ==============================================
# é¡µé¢ç•Œé¢é…ç½®
# ==============================================
st.set_page_config(
    page_title="æ™ºèƒ½è€ƒç ”æ‹©æ ¡åŠ©æ‰‹",
    page_icon="ğŸ“",
    layout="centered",
    initial_sidebar_state="expanded"
)

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("ğŸ”§ ç³»ç»Ÿé…ç½®", divider="rainbow")
    api_vendor = st.radio(
        "AIæœåŠ¡æä¾›å•†",
        options=['OpenAI', 'deepseek'],
        index=0,
        horizontal=True
    )

    if api_vendor == 'OpenAI':
        base_url = st.selectbox(
            "APIç«¯ç‚¹",
            options=[
                'https://api.openai.com/v1',
                'https://twapi.openai-hk.com/v1'
            ],
            index=0
        )
        model_options = ['gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo']
    else:
        base_url = 'https://api.deepseek.com'
        model_options = ['deepseek-chat', 'deepseek-v2']

    model_name = st.selectbox(
        "AIæ¨¡å‹",
        options=model_options,
        index=0,
        help="æ›´å¼ºå¤§çš„æ¨¡å‹èƒ½æä¾›æ›´ç²¾å‡†çš„å»ºè®®"
    )

    st.divider()
    st.header("ğŸ“‹ è€ƒç”Ÿæ¡£æ¡ˆ", divider="rainbow")
    user_score = st.slider(
        "åˆè¯•æ€»åˆ†",
        min_value=200,
        max_value=500,
        value=350,
        step=1,
        help="æ”¿æ²»+è‹±è¯­+ä¸“ä¸šè¯¾æ€»åˆ†ï¼ˆç®¡ç†ç±»è”è€ƒç­‰ç‰¹æ®Šè€ƒè¯•é™¤å¤–ï¼‰"
    )
    user_province = st.selectbox(
        "ç›®æ ‡é™¢æ ¡çœä»½",
        options=PROVINCES,
        index=0,
        help="ä¸åŒåœ°åŒºé˜…å·æ¾ç´§åº¦å­˜åœ¨å·®å¼‚"
    )
    user_subject = st.radio(
        "å­¦ç§‘é—¨ç±»",
        options=SUBJECT_TYPES,
        index=0,
        horizontal=True
    )
    user_interests = st.text_area(
        "ç ”ç©¶æ–¹å‘",
        placeholder=INTEREST_EXAMPLES,
        help="å»ºè®®ç»†åŒ–åˆ°äºŒçº§å­¦ç§‘ï¼ˆå¦‚ï¼šäººå·¥æ™ºèƒ½æ–¹å‘ï¼‰",
        height=100
    )

# ä¸»ç•Œé¢
st.title("ğŸ“ æ™ºèƒ½è€ƒç ”æ‹©æ ¡åŠ©æ‰‹")
st.caption("AIé©±åŠ¨çš„è€ƒç ”å’¨è¯¢ç³»ç»Ÿ | æ•°æ®ä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥å„æ ¡ç ”æ‹›ç½‘ä¸ºå‡†")

# åˆå§‹åŒ–å¯¹è¯
if 'messages' not in st.session_state:
    welcome_msg = """æ‚¨å¥½ï¼æˆ‘æ˜¯è€ƒç ”æ‹©æ ¡åŠ©æ‰‹å°ç ”ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

1. å…ˆåœ¨å·¦ä¾§å¡«å†™ã€è€ƒç”Ÿæ¡£æ¡ˆã€‘
2. ç„¶åæé—®ï¼Œä¾‹å¦‚ï¼š
   - 350åˆ†èƒ½ä¸Šå“ªäº›211è®¡ç®—æœºé™¢æ ¡ï¼Ÿ
   - æ¨èé•¿ä¸‰è§’åœ°åŒºçš„é‡‘èä¸“ç¡•é™¢æ ¡
   - è¿™ä¸ªåˆ†æ•°æŠ¥è€ƒ985æœ‰å¸Œæœ›å—ï¼Ÿ"""
    st.session_state.messages = [{"role": "ai", "content": welcome_msg}]

# æ˜¾ç¤ºå¯¹è¯å†å²
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# äº¤äº’å¤„ç†
if user_input := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    if not all([user_province, user_subject, user_interests]):
        st.error("è¯·å…ˆå®Œå–„å·¦ä¾§çš„è€ƒç”ŸåŸºæœ¬ä¿¡æ¯ï¼")
        st.stop()

    st.session_state.messages.append({"role": "human", "content": user_input})
    st.chat_message("human").write(user_input)

    with st.status("ğŸ” æ­£åœ¨æ™ºèƒ½åˆ†æ...", expanded=True) as status:
        try:
            advice_gen = get_advice(
                question=user_input,
                score=user_score,
                province=user_province,
                interests=user_interests,
                subject_type=user_subject
            )

            response = st.chat_message("ai").write_stream(advice_gen)
            st.session_state.messages.append({"role": "ai", "content": response})

            status.update(label="âœ… åˆ†æå®Œæˆ", state="complete", expanded=False)
        except Exception as exc:
            st.error(f"ç³»ç»Ÿé”™è¯¯: {str(exc)}")
            st.session_state.messages.append({
                "role": "ai",
                "content": f"âš ï¸ ç³»ç»Ÿé‡åˆ°é”™è¯¯ï¼Œè¯·ç¨åå†è¯•\né”™è¯¯è¯¦æƒ…ï¼š{type(exc).__name__}"
            })